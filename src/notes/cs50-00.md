---
path: "/CS50-00"
date: "2021-05-18"
title: "CS50 Week 0: Scratch"
tags:
  - CS50
  - C
description: "On binary, encoding, algorightms and more."
---

- 🔗 [Course Website](https://cs50.harvard.edu/x/2021/weeks/0/)

## On binary

**🤔 What does binary mean?**

- **Binary** is the numbering system that computers use in order to represent on and off. On is 1, and off is 0.
- Modern computers use a million tiny switches called **transistors** that can be turned on and off.

- A single digit in binary is known as a binary digit. Or, simply, a **bit**.

- 8 bits (8 digits) represent a **byte**.
- **Unary** is a system where each digit represents a single value of one.

**🤔 How about 8-bit vs 16-bit machines?**

- Different computers can process a different number of bits at a time.
- An **8-bit machine** breaks up and processes 8 bits at a time.
- A **16-bit machine** would break up and process 16 bits at a time. The number of bits that are processed at a time is known as a computer word, so we can think of bits as the “letters” that make up a computer word.
- Most computers now have a word length of 32 or 64 bits.
- In conclusion: this means that your machine passes around and processes 32 or 64 bits at a time. In other words, your computer processes binary strings that are 32 or 64 digits long!

## On encoding

🔗 Mostly based on this [article](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/).

🤔 **And what is encoding?**

- Encoding is a standardized way of translating between two things.

- **ASCII encoding** is a set of rules that allows us to translate certain characters into decimal numbers.

- ASCII can represent every character using a number between 32 and 127. Space is 32, the letter “A” is 65... These can be stored in 7 bits (meaning numbers 128 - 255 were up for grabs). Codes below 32 were for control characters.

- In the ANSI standard, everybody agreed on what to do below 128, which was pretty much the same as ASCII, but there were lots of different ways to handle the characters from 128 and on up, depending on where you lived. These different systems were called code pages.

🤔 **What is UNICODE?**

- UNICODE is a superset of ASCII
- Unicode was an effort to create a single character set that included every reasonable writing system on the planet and some make-believe ones like Klingon, too.

- In Unicode, a letter maps to something called a code point.

- Every platonic letter in every alphabet is assigned a magic number by the Unicode consortium, which is written like this: U+0639. This magic number is called a code point.

- `Hello` is an equivalent of `U+0048 U+0065 U+006C U+006C U+006F.`

**🤔 What is UTF-8?**

- UTF-8 was another system for storing your string of Unicode code points in memory using 8-bit bytes.

- In UTF-8, every code point from 0-127 is stored in a single byte.
- Only code points 128, and above are stored using 2, 3, in fact, up to 6 bytes.

- This has the neat side effect that English text looks exactly the same in UTF-8 as it did in ASCII.

## On images, videos, sounds

- **Pixels** are the dots, the squares on our screen.
- The **resolution** is the number of pixels there are, horizontally and vertically, so a high-resolution image will have more pixels and require more bytes to be stored.
- **Videos** are made up of many images, changing multiple times a second to give us the appearance of motion.
- **Music** can be represented with bits, too, with mappings of numbers to notes and durations, or more complex mappings of bits to sound frequencies at each moment of time.

## On algorithms

- An algorithm is a set of instructions for solving a problem.

- `input -> algorithms -> output`

- **Pseudocode** is a representation of an algorithm in a human language.

**More links:**

- [On the history of **C**](https://arstechnica.com/features/2020/12/a-damn-stupid-thing-to-do-the-origins-of-c/)

- [The EDSAC job queue](https://www.youtube.com/watch?v=6v4Juzn10gM)
